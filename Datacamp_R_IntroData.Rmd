---
title: "DataCamp_R_IntroData"
output: html_notebook
---
Chapter 1

n the video, you saw how to load the hsb2 dataset into R using the data() function and how to preview its contents with str().

In this exercise, you'll practice on another dataset, email50, which contains a subset of incoming emails for the first three months of 2012 for a single email account. You will examine the structure of this dataset and determine the number of rows (observations) and columns (variables).

Instructions
Load the email50 dataset with the data() function.
View the structure of this dataset with the str() function. How many observations and variables are there?

```{r}
# Load data

library(openintro)
library(dplyr)
library(ggplot2)
data(email50)


# View its structure

str(email50)
```
Recall from the video that the glimpse() function from dplyr provides a handy alternative to str() for previewing a dataset. In addition to telling you the number of observations and variables, it shows the name and type of each column, along with a neatly printed preview of its values.

Let's have another look at the email50 data, so you can practice identifying variable types.

Instructions
Use the glimpse() function to view the variables in the email50 dataset. Identify each variable as either numerical or categorical, and further as discrete or continuous (if numerical) or ordinal or not ordinal (if categorical).
```{r}
# Glimpse email50
glimpse(email50)
```

Filtering based on a factor

Categorical data are often stored as factors in R. In this exercise, you'll get some practice working with a factor variable, number, from the email50 dataset. This variable tells you what type of number (none, small, or big) an email contains.

Recall from the video that the filter() function from dplyr allows you to filter a dataset to create a subset containing only certain levels of a variable. For example, the following code filters the mtcars dataset for cars containing 6 cylinders:

mtcars %>%
  filter(cyl == 6)
Instructions
Create a new dataset called email50_big that is a subset of the original email50 dataset containing only emails with "big" numbers. This information is stored in the number variable.
Report the dimensions of email50_big using the glimpse() function again. How many emails contain big numbers?
```{r}
# Subset of emails with big numbers: email50_big

email50_big <- email50  %>%
  filter(number == "big")

# Glimpse the subset

glimpse(email50_big)
```
Complete filtering based on a factor

The droplevels() function removes unused levels of factor variables from your dataset. As you saw in the video, it's often useful to determine which levels are unused (i.e. contain zero values) with the table() function.

In this exercise, you'll see which levels of the number variable are dropped after applying the droplevels() function.

Instructions
Make a table() of the number variable in the email50_big dataset. Which two levels are unused?
Apply the droplevels() function to the number variable. Assign the result back to email50_big$number.
Remake the table() of the number variable in the email50_big dataset. How is this output different from the first?
```{r}

# Table of number variable

table(email50_big$number)

# Drop levels

email50_big$number <- droplevels(email50_big$number)

# Another table of number variable

table(email50_big$number)
```

Discretize a different variable

In this exercise, you will create a categorical version of the num_char variable in the email50 dataset, which tells you the number of characters in an email, in thousands. This new variable will have two levels—"below median" and "at or above median"—depending on whether an email has less than the median number of characters or equal to or more than that value.

The median marks the 50th percentile, or midpoint, of a distribution, so half of the emails should fall in one category and the other half in the other. You will learn more about the median and other measures of center in the next course in this series.

Instructions
The email50 dataset is available in your workspace.

Find the median number of characters in the emails and store the result as med_num_char.
Create a new variable called num_char_cat, which discretizes the num_char variable into "below median" or "at or above median". Use the mutate() function from dplyr to accomplish this.
Apply table() to determine how many emails are in each category and evaluate whether these counts match the expected numbers.
```{r}
# Calculate median number of characters: med_num_char

med_num_char <- median(email50$num_char)

# Create num_char_cat variable in email50

email50 <- email50 %>%
  mutate(num_char_cat = ifelse(num_char < med_num_char, "below median", "at or above median"))

# Count emails in each category

table(email50$num_char_cat)
```
Combining levels of a different factor

Another common way of creating a new variable based on an existing one is by combining levels of a categorical variable. For example, the email50 dataset has a categorical variable called number with levels "none", "small", and "big", but suppose you're only interested in whether an email contains a number. In this exercise, you will create a variable containing this information and also visualize it.

For now, do your best to understand the code we've provided to generate the plot. We will go through it in detail in the next video.

Instructions
Create a new variable in email50 called number_yn that is "no" if there is no number in the email and "yes" if there is a small or a big number. The ifelse() function may prove useful here.
Run the code provided to visualize the distribution of the number_yn variable.
```{r}
# Create number_yn column in email50


email50 <- email50 %>%
  mutate(number_yn = ifelse(number == "none", "no", "yes"))

# Visualize number_yn

ggplot(email50, aes(x = number_yn)) +
  geom_bar()

```
Visualizing numerical and categorical data

In this exercise, you will visualize the relationship between two numerical variables from the email50 dataset, conditioned on whether or not the email was spam.

Recall that in the ggplot() function, the first argument gives the dataset, then the aesthetics map the variables to certain features of the plot, and finally the geom_*() layer informs the type of plot you want to make. In this exercise, you will make a scatterplot by adding the geom_point() layer to your ggplot() call.

Instructions
Create a scatterplot of number of exclamation points in the email message (exclaim_mess) vs. number of characters (num_char).

Color points by whether or not the email is spam.
Note that the spam variable is stored as numerical (0/1) but you want to use it as a categorical variable in this plot. To do this, you need to force R to think of it as such with the factor() function.
Based on the plot, what's the relationship between these variables?
```{r}
# Load ggplot2


# Scatterplot of exclaim_mess vs. num_char

ggplot(email50, aes(x = num_char, y = exclaim_mess, color = factor(spam))) +
  geom_point()
```
Identify the type of study

Next, let's take a look at data from a different study on country characteristics. You'll load the data first and view it, then you'll be asked to identify the type of study. Remember, an experiment requires random assignment.

Instructions
Load the gapminder data. This dataset comes from the gapminder R package, which has already been loaded for you.
View the variables in the dataset with glimpse().
If these data come from an observational study, assign "observational" to the type_of_study variable. If experimental, assign "experimental".
```{r}
# Load data

library(gapminder)

data(gapminder)

# Glimpse data
glimpse(gapminder)

# Identify type of study
type_of_study <- "observational"
```
Number of males and females admitted

In order to calculate the number of males and females admitted, we will introduce two new functions: count() from the dplyr package and spread() from the tidyr package.

In one step, count() allows you to group the data by certain attributes (in this case, admission status and gender) and then counts the number of observations in each category.

spread() simply reorganizes the output across columns based on a key-value pair, where a pair contains a key that explains what the information describes and a value that contains the actual information. spread() takes the name of the dataset as its first argument, the name of the key column as its second argument, and the name of the value column as its third argument, all specified without quotation marks.

Instructions
Use the ucb_admit dataset (which is already pre-loaded) and the count() function to determine the total number of males and females admitted. Assign the result to ucb_counts.
Print ucb_counts to the console.
Then, use the spread() function to spread the output across columns based on admission status (key) and n (value).
```{r}

# Load packages
library(dplyr)
library(tidyr)

# Count number of male and female applicants admitted
ucb_counts <- ucb_admit %>%
  count(Gender, Admit)

# View result
ucb_counts
  
# Spread the output across columns
ucb_counts %>%
  spread(Admit, n)

```
Proportion of males admitted overall

You can now calculate the percentage of males admitted. To do so, you will create a new variable with mutate() from the dplyr package.

Instructions
dplyr and tidyr have been loaded for you.

Use the code from the previous exercise to construct a table of counts of admission status and gender.
Then, use the mutate() function create a new variable, Perc_Admit, which is the ratio of those admitted, Admitted, to all applicants of that gender, (Admitted + Rejected).
Which gender has a higher admission rate, male or female?
```{r}
ucb_admit %>%
  # Table of counts of admission status and gender
  count(Gender,Admit) %>%
  # Spread output across columns based on admission status
  spread(Admit,n) %>%
  # Create new variable
  mutate(Perc_Admit = Admitted / ((Admitted + Rejected)))
```
Proportion of males admitted for each department

Next you'll make a table similar to the one you constructed earlier, except you will first group the data by department. Then, you'll use this table to calculate the proportion of males admitted in each department.

Instructions
dplyr and tidyr have been loaded for you.

Use the code from earlier to create a table of counts of admission status and gender, but this time group first by Dept. Assign this result to admit_by_dept.
Print admit_by_dept to the console.
Calculate the percentage of those admitted in each department, Perc_Admit, by applying the mutate() function to admit_by_dept.
```{r}
ucb_admit %>%
  count(Dept,Gender,Admit) %>%
  spread(Admit,n)
```

Simple random sample in R

Suppose you want to collect some data from a sample of eight states. A list of all states and the region they belong to (Northeast, Midwest, South, West) are given in the us_regions data frame.

Instructions
The dplyr package and us_regions data frame have been loaded for you.

Use simple random sampling to select eight states from us_regions. Save this sample in a data frame called states_srs.
Count the number of states from each region in your sample.
```{r}
# Simple random sample: states_srs
states_srs <- us_regions  %>%
  sample_n(size = 8)

# Count states by region
states_srs %>%
  group_by(region) %>%
  count()
```

Stratified sample in R

In the last exercise, you took a simple random sample of eight states. However, as you may have noticed when you counted the number of states selected from each region, this strategy is unlikely to select an equal number of states from each region. The goal of stratified sampling is to select an equal number of states from each region.

Instructions
The dplyr package has been loaded for you and us_regions is still available in your workspace.

Use stratified sampling to select a total of eight states, where each stratum is a region. Save this sample in a data frame called states_str.
Count the number of states from each region in your sample to confirm that each region is represented equally in your sample.

```{r}
# Stratified sample
states_str <- us_regions  %>%
  group_by(region) %>%
  sample_n(size = 2)

# Count states by region
states_str %>%
   group_by(region) %>%
   count()
```
Inspect the data

The purpose of this chapter is to give you an opportunity to apply and practice what you've learned on a real world dataset. For this reason, we'll provide a little less guidance than usual.

The data from the study described in the video are available in your workspace as evals. Let's take a look!

Instructions
Inspect the evals data frame using techniques you learned in previous chapters. Use an approach that shows you how many observations and variables are included in the dataset.
```{r}
# Inspect evals

dim(evals)[1]

dim(evals)[2]
```
Identify variable types

It's always useful to start your exploration of a dataset by identifying variable types. The results from this exercise will help you design appropriate visualizations and calculate useful summary statistics later in your analysis.

Instructions
Explore the evals data once again with the following goals in mind:
Identify each variable as numerical or categorical.
If numerical, determine if discrete or continuous.
If categorical, determine if ordinal or not.
We've created a vector of variable names in the editor called cat_vars. To test your understanding of the data, remove the names of any variables that are not categorical.
```{r}
# Inspect variable types
glimpse(evals)

# Remove non-factor variables from this vector
cat_vars <- c( "rank", "ethnicity", "gender", "language", "cls_level", "cls_profs", "cls_credits",
               "pic_outfit", "pic_color")
```
Recode a variable

The cls_students variable in evals tells you the number of students in the class. Suppose instead of the exact number of students, you're interested in whether the class is

"small" (18 students or fewer),
"midsize" (19 - 59 students), or
"large" (60 students or more).
Since you'd like to have three distinct levels (instead of just two), you will need a nested call to ifelse(), which means that you'll call ifelse() a second time from within your first call to ifelse(). We've provided some scaffolding for you in the editor—see if you can figure it out!

Instructions
Recode the cls_students variable into a new variable, cls_type, having the three levels described above. Save the resulting data frame (with the new variable) as evals.
What type of variable is cls_type?
```{r}
# Recode cls_students as cls_type: evals
evals <- evals  %>%
  # Create new variable
  mutate(cls_type = ifelse(cls_students<=18 , "small", 
                      ifelse(cls_students>=60, "large", "midsize")))
```

Create a scatterplot

The bty_avg variable shows the average beauty rating of the professor by the six students who were asked to rate the attractiveness of these faculty. The score variable shows the average professor evaluation score, with 1 being very unsatisfactory and 5 being excellent.

Instructions
Use ggplot() to create a scatterplot displaying the relationship between these two variables.
How would you describe the relationship apparent in this visualization?
```{r}
# Scatterplot of score vs. bty_avg
ggplot(evals, aes (x =bty_avg , y=score)) + geom_point()
```
Create a scatterplot, with an added layer

Suppose you are interested in evaluating how the relationship between a professor's attractiveness and their evaluation score varies across different class types (small, midsize, and large).

Instructions
Recreate your visualization from the previous exercise, but this time coloring the points by class type.
How would you describe the relationship apparent in this visualization?
```{r}

# Scatterplot of score vs. bty_avg colored by cls_type
ggplot(evals, aes(x =bty_avg , y=score,color = cls_type)) + geom_point()
```
